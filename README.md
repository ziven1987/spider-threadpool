spider-threadpool
=================

使用线程池和队列完成一个deep查找web url的例子

功能描述：

1、指定网站爬取指定深度的页面，将包含指定关键词的页面内容存放到sqlite3数据库文件中

2、程序每隔10秒在屏幕上打印进度信息

3、支持线程池机制，并发爬取网页

4、己需要深刻理解该程序所涉及到的各类知识点

5、需要自己实现线程池

实现思路：

需要对深度查找有一定的了解，实际上就是在一个a连接得到以后，通过它href属性得到下一个连接，进入后在重复之前操作，直到不能在深入为止，url的存储放在消息队列中，通过一个readurl变量来区分是否已经查找过。

注意事项：

1.编码问题：默认的编码是unicode，但是使用在调试使用时，还是会有中文乱码的问题，最好在解析html文件时，使用模块BeautifulSoup(html, fromEncoding='utf-8')定义好编码格式。

2.效率问题：由于访问url可能会有延迟、超时等影响，如果使用线性的爬虫查找，效率会非常的慢，所以尽量要使用线程与队列，这样并发的执行会提高效率。

3.异常处理：实际的工作中，异常处理很重要，所以在容易出现异常的地方要进行异常处理。

4.输出log：log的使用可以帮助我们调试，由于在线程中，调试不是很方便，使用log可以很好的帮助我们得到有用的输出信息以及异常信息。
